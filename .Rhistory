plot(iris_pred ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=testData, xlab="Observed",ylab="Predicted")
abline(a=0, b=1)
iris_pred <- predict(iris_prune, newdata=testData)
iris_pred
plot(iris_pred[,1] ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=testData, xlab="Observed",ylab="Predicted")
plot(iris_pred[,1] ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=testData, xlab="Observed",ylab="Predicted")
abline(a=0, b=1)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData <- iris[ind==1,]
testData <- iris[ind==2,]
library(randomForest)
rf <- randomForest(Species ~ ., data=trainData, ntree=100, proximity=TRUE)
table(predict(rf), trainData$Species)
print(rf)
attributes(rf)
plot(rf)
png('random_forest.png')
plot(rf)
dev.off()
importance(rf)
varImpPlot(rf)
irisPred <- predict(rf, newdata=testData)
table(irisPred, testData$Species)
plot(margin(rf, testData$Species))
png('random_forest_2.png')
plot(margin(rf, testData$Species))
dev.off()
function (package, help, pos = 2, lib.loc = NULL, character.only = FALSE,
library(fpc)
setwd('C:\\Users\\Ivan.Liuyanfeng\\Desktop\\ata_Mining_Work_Space\\rdatamining')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
adData
diagnosis
predictors
head(diagnosis)
head(predictors)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
head(testIndex)
testIndex = createDataPartition(diagnosis, p = 0.50,list=T)
head(testIndex)
head(testIndex)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
require(Hmisc)
a <- cut2(inTrain)
a
concrete$a <- cut2(inTrain)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
concrete$SuperPlasticizer
concrete$SuperPlasticizer
colnames(concrete)
concrete$Superplasticizer
hist(concrete$Superplasticizer)
hist(log(concrete$Superplasticizer))
hist(concrete$Superplasticizer)
par(mfcol=c(1,2))
hist(log(concrete$Superplasticizer))
hist(concrete$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(AlzheimerDisease)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
str(training)
str(training[,57:68])
str(training[,58:69])
preProcess(training[,58:69], method='pca')
pca <- preProcess(training[,58:69], method='pca')
plot(pca)
predict(training[,58:69],pca)[,1]
predict(pca,training[,58:69])[,1]
predict(pca,training[,58:69])
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
concrete$Superplasticizer
par(mfcol=c(1,2))
hist(log(concrete$Superplasticizer))
hist(concrete$Superplasticizer)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=F)
head(testIndex)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
require(Hmisc)
plot(training$Compre
plot(training$CompressiveStrength,pch=1,col=cut2(training$FlyAsh,m=20))
cut2(training$FlyAsh
)
plot(training$CompressiveStrength,pch=1,col=cut2(training$Age,m=20))
plot(training$CompressiveStrength,pch=1,col=cut2(training$Cement,m=20))
pca <- preProcess(training[,58:69], method='pca', pcaComp=2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training[,58:69])
pca <- preProcess(training[,58:69], method='pca', pcaComp=2)
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
pca.p
pca <- preProcess(training[,58:69], method='pca')
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training[,58:69])
pca <- preProcess(training[,58:69], method='pca')
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
prcomp(training[,58:69])
pca$rotation
plot(prcomp(training[,58:69]))
svd1 <- svd(prcomp(training[,58:69]))
svd1 <- svd(scale(prcomp(training[,58:69])))
scale(prcomp(training[,58:69]))
svd1 <- svd(scale(training[,58:69]))
svd1
plot(svd1$d)
plot(svd1$d^2/sum(svd1$d^2))
svd1 <- svd(training[,58:69])
plot(svd1$d^2/sum(svd1$d^2))
scale
svd1 <- svd(scale(training[,58:69]))
plot(svd1$d^2/sum(svd1$d^2))
pca[,1]
pca
pca$rotation
plot(svd1$d^2/sum(svd1$d^2))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
fit <- svm(CompressiveStrength~., training)
pred <- predict(fit, testing)
# confusionMatrix(as.vector(pred), testing$CompressiveStrength)
sum(sqrt((pred-testing$CompressiveStrength)^2))
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
fit <- svm(CompressiveStrength~., training)
pred <- predict(fit, testing)
# confusionMatrix(as.vector(pred), testing$CompressiveStrength)
sum(sqrt((pred-testing$CompressiveStrength)^2))
sqrt(sum((pred-testing$CompressiveStrength)^2))
sqrt(107.44)
?colSums
?dgamma
?lm
?predict
?dgamma
?predict
?dgamma
pnorm(70, mean=80, sd=10, lower.tail=T)
pnorm(70, mean=80, sd=10, lower.tail=F)
qnorm(.95, mean=1000, sd=75)
qnorm(.95, mean=1000, sd=75, lower.tail = F)
qnorm(.95, mean=1000, sd=75, lower.tail = F)
T
qnorm(.95, mean=1000, sd=75, lower.tail = T)
qnorm(.95, mean=1100, sd=75, lower.tail = T)
qnorm(.95, mean=1100, sd=75, lower.tail = F)
qnorm(.95, mean=1100, sd=75, lower.tail = T)
pbinom(3, size = 5, prob = 0.5, lower.tail = FALSE)
ppois(2, lambda = 500 * 0.01)
pbinom(2, size = 500, prob = 0.01)
ppois(10, lambda = 5 * 3)
qnorm(.95, mean=1100, sd=75/sqrt(100), lower.tail = T)
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3
)# 9
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(.5, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(qnorm(.5, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(qnorm(1000, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(1000, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(1, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.5, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.1, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.9, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.9, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
round(pnorm(0.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
51
round(pnorm(0.51, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
round(pnorm(0.5, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
setwd("C:\\Users\\Ivan.Liuyanfeng\\Desktop\\Data_Mining_Work_Space\\Data-Science-Regression-Models")
data(diamond)
library(ggplot2)
data(diamond)
library(UsingR)
data(diamond)
plot(diamond$carat, diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(lm(price ~ carat, data = diamond), lwd = 2)
setwd("C:\\Users\\Ivan.Liuyanfeng\\Desktop\\Data_Mining_Work_Space\\Data-Science-Regression-Models")
library(UsingR)
data(diamond)
png("slm.png")
plot(diamond$carat, diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(lm(price ~ carat, data = diamond), lwd = 2)
dev.off()
fit <- lm(price ~ carat, data = diamond)
coef(fit)
fit2 <- lm(price ~ I(carat - mean(carat)), data = diamond)
coef(fit2)
fit3 <- lm(price ~ I(carat * 10), data = diamond)
coef(fit3)
newx <- c(0.16, 0.27, 0.34)
coef(fit)[1] + coef(fit)[2] * newx
coef(fit)[1]
coef(fit)[2]
predict(fit, newdata = data.frame(carat = newx))
coef(fit)
coef(fit3)
plot(diamond$carat, diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(fit, lwd = 2)
points(diamond$carat, predict(fit), pch = 19, col = "red")
lines(c(0.16, 0.16, 0.12),
c(200, coef(fit)[1] + coef(fit)[2] * 0.16,
coef(fit)[1] + coef(fit)[2] * 0.16))
predict(fit)
lines(c(0.27, 0.27, 0.12),
c(200, coef(fit)[1] + coef(fit)[2] * 0.27,
coef(fit)[1] + coef(fit)[2] * 0.27))
lines(c(0.34, 0.34, 0.12),
c(200, coef(fit)[1] + coef(fit)[2] * 0.34,
coef(fit)[1] + coef(fit)[2] * 0.34))
text(newx, rep(250, 3), labels = newx, pos = 2)
png('slm2.png')
plot(diamond$carat, diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(fit, lwd = 2)
points(diamond$carat, predict(fit), pch = 19, col = "red")
lines(c(0.16, 0.16, 0.12),
c(200, coef(fit)[1] + coef(fit)[2] * 0.16,
coef(fit)[1] + coef(fit)[2] * 0.16))
lines(c(0.27, 0.27, 0.12),
c(200, coef(fit)[1] + coef(fit)[2] * 0.27,
coef(fit)[1] + coef(fit)[2] * 0.27))
lines(c(0.34, 0.34, 0.12),
c(200, coef(fit)[1] + coef(fit)[2] * 0.34,
coef(fit)[1] + coef(fit)[2] * 0.34))
text(newx, rep(250, 3), labels = newx, pos = 2)
dev.off()
require(UsingR)
data(diamond)
y <- diamond$price; x <- diamond$carat; n <- length(y)
y
x
n
fit <- lm(y ~ x)
fit
e <- resid(fit)
e
yhat <- predict(fit)
yhat
y - yhat
e -(y - yhat
)
max(abs(e -(y - yhat)))
coef(fit)[1] - coef(fit)[2] * x
max(abs(e - (y - coef(fit)[1] - coef(fit)[2] * x)))
plot(diamond$carat, diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(fit, lwd = 2)
for (i in 1 : n)
lines(c(x[i], x[i]), c(y[i], yhat[i]), col = "red" , lwd = 2)
png('residual1.png')
plot(diamond$carat, diamond$price,
xlab = "Mass (carats)",
ylab = "Price (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(fit, lwd = 2)
for (i in 1 : n)
lines(c(x[i], x[i]), c(y[i], yhat[i]), col = "red" , lwd = 2)
dev.off()
plot(diamond$carat, e,
xlab = "Mass (carats)",
ylab = "Residuals (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(h = 0, lwd = 2)
for (i in 1 : n)
lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
png('residual2.png')
plot(diamond$carat, e,
xlab = "Mass (carats)",
ylab = "Residuals (SIN $)",
bg = "lightblue",
col = "black", cex = 1.1, pch = 21,frame = FALSE)
abline(h = 0, lwd = 2)
for (i in 1 : n)
lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
dev.off()
e
x <- runif(100, -3, 3); y <- x + sin(x) + rnorm(100, sd = .2);
plot(x, y); abline(lm(y ~ x))
plot(x, resid(lm(y ~ x)));
abline(h = 0)
png("residual3.png")
par(mfcol=c(1,2))
plot(x, y); abline(lm(y ~ x))
plot(x, resid(lm(y ~ x)));
abline(h = 0)
dev.off()
par(mfcol=c(1,2))
plot(x, y); abline(lm(y ~ x))
plot(x, resid(lm(y ~ x)));
abline(h = 0)
x <- runif(100, 0, 6); y <- x + rnorm(100, mean = 0, sd = .001 * x);
plot(x, y); abline(lm(y ~ x))
plot(x, resid(lm(y ~ x)));
abline(h = 0)
x <- runif(100, 0, 6); y <- x + rnorm(100, mean = 0, sd = .001 * x);
png("residual4.png")
plot(x, y); abline(lm(y ~ x))
plot(x, resid(lm(y ~ x)));
abline(h = 0)
dev.off()
y <- diamond$price; x <- diamond$carat; n <- length(y)
fit <- lm(y ~ x)
summary(fit)$sigma
sqrt(sum(resid(fit)^2) / (n - 2))
example(anscombe)
library(UsingR); data(diamond)
y <- diamond$price; x <- diamond$carat; n <- length(y)
beta1 <- cor(y, x) * sd(y) / sd(x)
beta1
cor(y, x)
sd(y)
sd(x)
beta0 <- mean(y) - beta1 * mean(x)
beta0
e <- y - beta0 - beta1 * x
e
sigma <- sqrt(sum(e^2) / (n-2))
sigma
ssx <- sum((x - mean(x))^2)
ssx
(x - mean(x))^2
seBeta0 <- (1 / n + mean(x) ^ 2 / ssx) ^ .5 * sigma
seBeta0
seBeta1 <- sigma / sqrt(ssx)
seBeta1
tBeta0 <- beta0 / seBeta0; tBeta1 <- beta1 / seBeta1
pBeta0 <- 2 * pt(abs(tBeta0), df = n - 2, lower.tail = FALSE)
pBeta1 <- 2 * pt(abs(tBeta1), df = n - 2, lower.tail = FALSE)
coefTable <- rbind(c(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, tBeta1, pBeta1))
coefTable
colnames(coefTable) <- c("Estimate", "Std. Error", "t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)", "x"
)
coefTable
coefTable
fit <- lm(y ~ x)
summary(fit)$coefficients
sumCoef <- summary(fit)$coefficients
sumCoef
sumCoef[1,1]
sumCoef[1,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[1, 2]
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2)
abline(fit, lwd = 2)
xVals <- seq(min(x), max(x), by = .01)
yVals <- beta0 + beta1 * xVals
se1 <- sigma * sqrt(1 / n + (xVals - mean(x))^2/ssx)
se2 <- sigma * sqrt(1 + 1 / n + (xVals - mean(x))^2/ssx)
lines(xVals, yVals + 2 * se1)
lines(xVals, yVals - 2 * se1)
lines(xVals, yVals + 2 * se2)
lines(xVals, yVals - 2 * se2)
par(mtcol=c(1,1))
par(mfcol=c(1,1))
# predictions intervals
png("intervals.png")
par(mfcol=c(1,1))
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2)
abline(fit, lwd = 2)
xVals <- seq(min(x), max(x), by = .01)
yVals <- beta0 + beta1 * xVals
se1 <- sigma * sqrt(1 / n + (xVals - mean(x))^2/ssx)
se2 <- sigma * sqrt(1 + 1 / n + (xVals - mean(x))^2/ssx)
lines(xVals, yVals + 2 * se1)
lines(xVals, yVals - 2 * se1)
lines(xVals, yVals + 2 * se2)
lines(xVals, yVals - 2 * se2)
dev.off()
par(mfcol=c(1,1))
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2)
abline(fit, lwd = 2)
xVals <- seq(min(x), max(x), by = .01)
yVals <- beta0 + beta1 * xVals
se1 <- sigma * sqrt(1 / n + (xVals - mean(x))^2/ssx)
se2 <- sigma * sqrt(1 + 1 / n + (xVals - mean(x))^2/ssx)
lines(xVals, yVals + 2 * se1)
lines(xVals, yVals - 2 * se1)
lines(xVals, yVals + 2 * se2)
lines(xVals, yVals - 2 * se2)
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2)
abline(fit, lwd = 2)
xVals <- seq(min(x), max(x), by = .01)
yVals <- beta0 + beta1 * xVals
se1 <- sigma * sqrt(1 / n + (xVals - mean(x))^2/ssx)
se2 <- sigma * sqrt(1 + 1 / n + (xVals - mean(x))^2/ssx)
lines(xVals, yVals + 2 * se1)
lines(xVals, yVals - 2 * se1)
lines(xVals, yVals + 2 * se2)
lines(xVals, yVals - 2 * se2)
se2
se1
newdata <- data.frame(x = xVals)
newdata
xVals
p1 <- predict(fit, newdata, interval = ("confidence"))
p2 <- predict(fit, newdata, interval = ("prediction"))
p1
p2
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2)
abline(fit, lwd = 2)
lines(xVals, p1[,2]); lines(xVals, p1[,3])
lines(xVals, p2[,2]); lines(xVals, p2[,3])
png("intervals2.png")
plot(x, y, frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2)
abline(fit, lwd = 2)
lines(xVals, p1[,2]); lines(xVals, p1[,3])
lines(xVals, p2[,2]); lines(xVals, p2[,3])
dev.off()
