rjson::fromJSON(
file = "http://bost.ocks.org/mike/sankey/energy.json"
)$links
),ncol = 3, byrow = TRUE)
nodes <- unlist(
rjson::fromJSON(
file = "http://bost.ocks.org/mike/sankey/energy.json"
)$nodes
)
nodes <- unlist(
nodes
#in form of source, target, value
links
links <- data.frame(links)
colnames(links) <- c("source", "target", "value")
links
links$source <- sapply(links$source, FUN = function(x) {return(as.character(nodes[x+1]))}) #x+1 since js starts at 0
links
links$target <- sapply(links$target, FUN = function(x) {return(nodes[x+1])}) #x+1 since js starts at 0
links
sankeyPlot <- rCharts$new()
sankeyPlot
sankeyPlot <- rCharts$new()
sankeyPlot$setLib('.')
sankeyPlot$setTemplate(script = "layouts/chart.html")
sankeyPlot$set(
data = links,
nodeWidth = 15,
nodePadding = 10,
layout = 32,
width = 960,
height = 500,
units = "TWh",
title = "Sankey Diagram"
)
sankeyPlot
library(plotly)
intall.packages("plotly")
install_github("ropensci/plotly")
library("devtools")
install_github("ropensci/plotly")
library(plotly)
p <- plotly(username='R-Demo-Account', key='yu680v5eii')
trace1 <- list(
x = c(1, 2, 3, 4, 5),
y = c(1, 3, 2, 3, 1),
mode = "lines+markers",
name = "'linear'",
line = list(shape = "linear"),
type = "scatter"
)
trace1
trace2 <- list(
x = c(1, 2, 3, 4, 5),
y = c(6, 8, 7, 8, 6),
mode = "lines+markers",
name = "'spline'",
text = c("tweak line smoothness<br>with 'smoothing' in line object", "tweak line smoothness<br>with 'smoothing' in line object", "tweak line smoothness<br>with 'smoothing' in line object", "tweak line smoothness<br>with 'smoothing' in line object", "tweak line smoothness<br>with 'smoothing' in line object", "tweak line smoothness<br>with 'smoothing' in line object"),
line = list(shape = "spline"),
type = "scatter"
)
trace3 <- list(
x = c(1, 2, 3, 4, 5),
y = c(11, 13, 12, 13, 11),
mode = "lines+markers",
name = "'vhv'",
line = list(shape = "vhv"),
type = "scatter"
)
trace4 <- list(
x = c(1, 2, 3, 4, 5),
y = c(16, 18, 17, 18, 16),
mode = "lines+markers",
name = "'hvh'",
line = list(shape = "hvh"),
type = "scatter"
)
trace5 <- list(
x = c(1, 2, 3, 4, 5),
y = c(21, 23, 22, 23, 21),
mode = "lines+markers",
name = "'vh'",
line = list(shape = "vh"),
type = "scatter"
)
trace6 <- list(
x = c(1, 2, 3, 4, 5),
y = c(26, 28, 27, 28, 26),
mode = "lines+markers",
name = "'hv'",
line = list(shape = "hv"),
type = "scatter"
)
data <- list(trace1, trace2, trace3, trace4, trace5, trace6)
daa
data
layout <- list(legend = list(
y = 0.5,
traceorder = "reversed",
font = list(size = 16),
yref = "paper"
))
response <- p$plotly(data, kwargs=list(layout=layout, filename="line-shapes", fileopt="overwrite"))
p <- plotly(username='ivanliu1989', key='clouds123')
response <- p$plotly(data, kwargs=list(layout=layout, filename="line-shapes", fileopt="overwrite"))
set_credentials_file("ivanliu1989", "i4quiodbde")
response <- p$plotly(data, kwargs=list(layout=layout, filename="line-shapes", fileopt="overwrite"))
py <- plotly()
ggiris <- qplot(Petal.Width, Sepal.Length, data = iris, color = Species)
r <- py$ggplotly(ggiris)
r$response$url
trace0 <- list(
x = c(1, 2, 3, 4),
y = c(10, 15, 13, 17)
)
trace1 <- list(
x = c(1, 2, 3, 4),
y = c(16, 5, 11, 9)
)
response <- py$plotly(trace0, trace1, kwargs=list(filename="basic-line", fileopt="overwrite"))
response$url
response <- py$plotly(data, kwargs=list(layout=layout, filename="line-shapes", fileopt="overwrite"))
url <- response$url
filename <- response$filename
url
filename
response$url
py$response$url
py$response
install.packages(c("car", "effects", "multcomp", "NLP", "party", "robCompositions", "XLConnect", "XLConnectJars"))
shiny::runApp('C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/shiny_app_pricing_management')
shinyapps::setAccountInfo(name='ivanliu1989', token='1E877F87A6C2DCCF5DE964D73F4875BE', secret='9srUXMP3o8jChzSaz9gMofZsoFn6a4HgxExyKyb1')
require(shinyapps)
deployApp()
data <- iris[,c(1,2,5)]
data(iris)
data <- iris[,c(1,2,5)]
data$Species <- factor(ifelse(data$Speices == 'setosa','rare','common'))
data$Species <- factor(ifelse(data$Species == 'setosa','rare','common'))
newData <- SMOTE(Species~.,data,perc.over=600)
require(DMwR)
data$Species
newData <- SMOTE(Species~.,data,perc.over=600)
table(newData$Species)
table(data$Species)
dim(iris)
name(iris)
names(iris)
str(iris)
attribute(iris)
attributes(iris)
iris[1:5,]
iris[1:10,3]
iris[1:10,1]
iris[,1][1:10]
summary(iris)
table(iris[,1])
table(iris[,5])
pie(table(iris[,5]))
var(iris[,1])
cov(iris[,1],iris[,3])
cor(iris[,1],iris[,3])
hist(iris[,1])
plot(density(iris[,3]))
plot(density(iris[,1]))
plot(iris[,1],iris[,3])
plot(iris[,1],iris[,2])
plot(iris)
pairs(iris)
library(party)
str(iris)
iris_ctree <- ctree(Species ~. , data=iris)
print(iris_ctree)
plot(iris_ctree)
plot(iris_ctree, type='simple')
png('decision_tree_1.png')
plot(iris_ctree)
dev.off()
png('decision_tree_2.png')
plot(iris_ctree, type='simple')
dev.off()
?ctree
newiris <- iris
newiris$Species <- NULL
(kc <- kmeans(newiris,3))
table(iris$Species, kc($cluster)
table(iris$Species, kc$cluster)
plot(newiris[c('Sepal.Length','Sepal.Width')], col=kc$cluster)
points(kc$centers[,c('Sepal.Length','Sepal.Width')],col=1:3,pch=8,cex=2)
png('kmeans.png')
plot(newiris[c('Sepal.Length','Sepal.Width')], col=kc$cluster)
points(kc$centers[,c('Sepal.Length','Sepal.Width')],col=1:3,pch=8,cex=2)
dev.off()
set.seed(1234)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData <- iris[ind==1,]
testData <- iris[ind==2,]
ind
myFormula <- Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width
iris_ctree <- ctree(myFormula, data=trainData)
table(predict(iris_ctree), trainData$Species)
print(iris_ctree)
plot(iris_ctree)
plot(iris_ctree, type="simple")
testPred <- predict(iris_ctree, newdata = testData)
table(testPred, testData$Species)
# by rpart
data("bodyfat", package = "mboost")
require(mboost)
data("bodyfat", package = "mboost")
dim(bodyfat)
set.seed(1234)
set.seed(1234)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData <- iris[ind==1,]
testData <- iris[ind==2,]
library(rpart)
iris_rpart <- rpart(myFormula, data = trainData,
+ control = rpart.control(minsplit = 10))
iris_rpart <- rpart(myFormula, data = trainData,control = rpart.control(minsplit = 10))
attributes(iris_rpart)
named list()
print(iris_rpart$cptable)
print(iris_rpart)
plot(iris_rpart)
text(iris_rpart, use.n=T)
opt <- which.min(iris_rpart$cptable[,"xerror"])
iris_prune <- prune(iris_rpart, cp = cp)
cp <- iris_rpart$cptable[opt, "CP"]
iris_prune <- prune(iris_rpart, cp = cp)
print(iris_prune)
plot(bodyfat_prune)
plot(iris_prune)
text(iris_prune, use.n=T)
iris_pred <- predict(iris_prune, newdata=testData)
iris_pred <- predict(iris_prune, newdata=testData)
plot(iris_pred ~ ., data=testData, xlab="Observed",
+ ylab="Predicted", ylim=xlim, xlim=xlim)
plot(iris_pred ~ ., data=testData, xlab="Observed",ylab="Predicted", ylim=xlim, xlim=xlim)
xlim <- range(iris[,1])
plot(iris_pred ~ ., data=testData, xlab="Observed",ylab="Predicted", ylim=xlim, xlim=xlim)
iris_pred
testData
plot(iris_pred ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=testData, xlab="Observed",ylab="Predicted", ylim=xlim, xlim=xlim)
iris_pred <- predict(iris_prune, newdata=testData)
plot(iris_pred ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=testData, xlab="Observed",ylab="Predicted")
abline(a=0, b=1)
iris_pred <- predict(iris_prune, newdata=testData)
iris_pred
plot(iris_pred[,1] ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=testData, xlab="Observed",ylab="Predicted")
plot(iris_pred[,1] ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data=testData, xlab="Observed",ylab="Predicted")
abline(a=0, b=1)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.7, 0.3))
trainData <- iris[ind==1,]
testData <- iris[ind==2,]
library(randomForest)
rf <- randomForest(Species ~ ., data=trainData, ntree=100, proximity=TRUE)
table(predict(rf), trainData$Species)
print(rf)
attributes(rf)
plot(rf)
png('random_forest.png')
plot(rf)
dev.off()
importance(rf)
varImpPlot(rf)
irisPred <- predict(rf, newdata=testData)
table(irisPred, testData$Species)
plot(margin(rf, testData$Species))
png('random_forest_2.png')
plot(margin(rf, testData$Species))
dev.off()
function (package, help, pos = 2, lib.loc = NULL, character.only = FALSE,
library(fpc)
setwd('C:\\Users\\Ivan.Liuyanfeng\\Desktop\\ata_Mining_Work_Space\\rdatamining')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
adData
diagnosis
predictors
head(diagnosis)
head(predictors)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
head(testIndex)
testIndex = createDataPartition(diagnosis, p = 0.50,list=T)
head(testIndex)
head(testIndex)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
require(Hmisc)
a <- cut2(inTrain)
a
concrete$a <- cut2(inTrain)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
concrete$SuperPlasticizer
concrete$SuperPlasticizer
colnames(concrete)
concrete$Superplasticizer
hist(concrete$Superplasticizer)
hist(log(concrete$Superplasticizer))
hist(concrete$Superplasticizer)
par(mfcol=c(1,2))
hist(log(concrete$Superplasticizer))
hist(concrete$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(AlzheimerDisease)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
str(training)
str(training[,57:68])
str(training[,58:69])
preProcess(training[,58:69], method='pca')
pca <- preProcess(training[,58:69], method='pca')
plot(pca)
predict(training[,58:69],pca)[,1]
predict(pca,training[,58:69])[,1]
predict(pca,training[,58:69])
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
concrete$Superplasticizer
par(mfcol=c(1,2))
hist(log(concrete$Superplasticizer))
hist(concrete$Superplasticizer)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=F)
head(testIndex)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
require(Hmisc)
plot(training$Compre
plot(training$CompressiveStrength,pch=1,col=cut2(training$FlyAsh,m=20))
cut2(training$FlyAsh
)
plot(training$CompressiveStrength,pch=1,col=cut2(training$Age,m=20))
plot(training$CompressiveStrength,pch=1,col=cut2(training$Cement,m=20))
pca <- preProcess(training[,58:69], method='pca', pcaComp=2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training[,58:69])
pca <- preProcess(training[,58:69], method='pca', pcaComp=2)
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
pca.p
pca <- preProcess(training[,58:69], method='pca')
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training[,58:69])
pca <- preProcess(training[,58:69], method='pca')
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
prcomp(training[,58:69])
pca$rotation
plot(prcomp(training[,58:69]))
svd1 <- svd(prcomp(training[,58:69]))
svd1 <- svd(scale(prcomp(training[,58:69])))
scale(prcomp(training[,58:69]))
svd1 <- svd(scale(training[,58:69]))
svd1
plot(svd1$d)
plot(svd1$d^2/sum(svd1$d^2))
svd1 <- svd(training[,58:69])
plot(svd1$d^2/sum(svd1$d^2))
scale
svd1 <- svd(scale(training[,58:69]))
plot(svd1$d^2/sum(svd1$d^2))
pca[,1]
pca
pca$rotation
plot(svd1$d^2/sum(svd1$d^2))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
fit <- svm(CompressiveStrength~., training)
pred <- predict(fit, testing)
# confusionMatrix(as.vector(pred), testing$CompressiveStrength)
sum(sqrt((pred-testing$CompressiveStrength)^2))
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
fit <- svm(CompressiveStrength~., training)
pred <- predict(fit, testing)
# confusionMatrix(as.vector(pred), testing$CompressiveStrength)
sum(sqrt((pred-testing$CompressiveStrength)^2))
sqrt(sum((pred-testing$CompressiveStrength)^2))
sqrt(107.44)
?colSums
?dgamma
?lm
?predict
?dgamma
?predict
?dgamma
pnorm(70, mean=80, sd=10, lower.tail=T)
pnorm(70, mean=80, sd=10, lower.tail=F)
qnorm(.95, mean=1000, sd=75)
qnorm(.95, mean=1000, sd=75, lower.tail = F)
qnorm(.95, mean=1000, sd=75, lower.tail = F)
T
qnorm(.95, mean=1000, sd=75, lower.tail = T)
qnorm(.95, mean=1100, sd=75, lower.tail = T)
qnorm(.95, mean=1100, sd=75, lower.tail = F)
qnorm(.95, mean=1100, sd=75, lower.tail = T)
pbinom(3, size = 5, prob = 0.5, lower.tail = FALSE)
ppois(2, lambda = 500 * 0.01)
pbinom(2, size = 500, prob = 0.01)
ppois(10, lambda = 5 * 3)
qnorm(.95, mean=1100, sd=75/sqrt(100), lower.tail = T)
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3
)# 9
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(.5, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(qnorm(.5, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(qnorm(1000, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(1000, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(1, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.5, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.1, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.9, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.9, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
round(pnorm(0.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
51
round(pnorm(0.51, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
round(pnorm(0.5, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
setwd("C:\\Users\\Ivan.Liuyanfeng\\Desktop\\Data_Mining_Work_Space\\Data-Science-Regression-Models")
n <- 100; x <- rnorm(n); x2 <- rnorm(n); x3 <- rnorm(n)
y <- x + x2 + x3 + rnorm(n, sd = .1)
e <- function(a, b) a - sum( a * b ) / sum( b ^ 2) * b
ey <- e(e(y, x2), e(x3, x2))
ex <- e(e(x, x2), e(x3, x2))
sum(ey * ex) / sum(ex ^ 2)
coef(lm(y ~ x + x2 + x3 - 1)) #the -1 removes the intercept term
ey <- e(e(y, x3), e(x2, x3))
ex <- e(e(x, x3), e(x2, x3))
sum(ey * ex) / sum(ex ^ 2)
coef(lm(y ~ x + x2 + x3 - 1)) #the -1 removes the intercept term
ey <- resid(lm(y ~ x2 + x3 - 1))
ex <- resid(lm(x ~ x2 + x3 - 1))
sum(ey * ex) / sum(ex ^ 2)
